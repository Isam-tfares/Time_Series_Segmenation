{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632d7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ruptures as rpt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4e5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating_change_point(true, prediction, metric='nab', numenta_time=None):\n",
    "    \"\"\"\n",
    "    true - both:\n",
    "                list of pandas Series with binary int labels\n",
    "                pandas Series with binary int labels\n",
    "    prediction - both:\n",
    "                      list of pandas Series with binary int labels\n",
    "                      pandas Series with binary int labels\n",
    "    metric: 'nab', 'binary' (FAR, MAR), 'average_delay'\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    def binary(true, prediction):      \n",
    "        \"\"\"\n",
    "        true - true binary series with 1 as anomalies\n",
    "        prediction - trupredicted binary series with 1 as anomalies\n",
    "        \"\"\"\n",
    "        def single_binary(true,prediction):\n",
    "            true_ = true == 1 \n",
    "            prediction_ = prediction == 1\n",
    "            TP = (true_ & prediction_).sum()\n",
    "            TN = (~true_ & ~prediction_).sum()\n",
    "            FP = (~true_ & prediction_).sum()\n",
    "            FN = (true_ & ~prediction_).sum()\n",
    "            return TP,TN,FP,FN\n",
    "            \n",
    "        if type(true) != type(list()):\n",
    "            TP,TN,FP,FN = single_binary(true,prediction)\n",
    "        else:\n",
    "            TP,TN,FP,FN = 0,0,0,0\n",
    "            for i in range(len(true)):\n",
    "                TP_,TN_,FP_,FN_ = single_binary(true[i],prediction[i])\n",
    "                TP,TN,FP,FN = TP+TP_,TN+TN_,FP+FP_,FN+FN_       \n",
    "    \n",
    "        f1 = round(TP/(TP+(FN+FP)/2), 2)\n",
    "        print(f'False Alarm Rate {round(FP/(FP+TN)*100,2)} %' )\n",
    "        print(f'Missing Alarm Rate {round(FN/(FN+TP)*100,2)} %')\n",
    "        print(f'F1 metric {f1}')\n",
    "        return f1\n",
    "    \n",
    "    def average_delay(detecting_boundaries, prediction):\n",
    "        \n",
    "        def single_average_delay(detecting_boundaries, prediction):\n",
    "            missing = 0\n",
    "            detectHistory = []\n",
    "            for couple in detecting_boundaries:\n",
    "                t1 = couple[0]\n",
    "                t2 = couple[1]\n",
    "                if prediction[t1:t2].sum()==0:\n",
    "                    missing+=1\n",
    "                else:\n",
    "                    detectHistory.append(prediction[prediction ==1][t1:t2].index[0]-t1)\n",
    "            return missing, detectHistory\n",
    "            \n",
    "        \n",
    "        if type(prediction) != type(list()):\n",
    "            missing, detectHistory = single_average_delay(detecting_boundaries, prediction)\n",
    "        else:\n",
    "            missing, detectHistory = 0, []\n",
    "            for i in range(len(prediction)):\n",
    "                missing_, detectHistory_ = single_average_delay(detecting_boundaries[i], prediction[i])\n",
    "                missing, detectHistory = missing+missing_, detectHistory+detectHistory_\n",
    "\n",
    "        add = pd.Series(detectHistory).mean()\n",
    "        print('Average delay', add)\n",
    "        print(f'A number of missed CPs = {missing}')\n",
    "        return add\n",
    "    \n",
    "    def evaluate_nab(detecting_boundaries, prediction, table_of_coef=None):\n",
    "        \"\"\"\n",
    "        Scoring labeled time series by means of\n",
    "        Numenta Anomaly Benchmark methodics\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        detecting_boundaries: list of list of two float values\n",
    "            The list of lists of left and right boundary indices\n",
    "            for scoring results of labeling\n",
    "        prediction: pd.Series with timestamp indices, in which 1 \n",
    "            is change point, and 0 in other case. \n",
    "        table_of_coef: pandas array (3x4) of float values\n",
    "            Table of coefficients for NAB score function\n",
    "            indeces: 'Standart','LowFP','LowFN'\n",
    "            columns:'A_tp','A_fp','A_tn','A_fn'\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Scores: numpy array, shape of 3, float\n",
    "            Score for 'Standart','LowFP','LowFN' profile \n",
    "        Scores_null: numpy array, shape 3, float\n",
    "            Null score for 'Standart','LowFP','LowFN' profile             \n",
    "        Scores_perfect: numpy array, shape 3, float\n",
    "            Perfect Score for 'Standart','LowFP','LowFN' profile  \n",
    "        \"\"\"\n",
    "        def single_evaluate_nab(detecting_boundaries, prediction, table_of_coef=None, name_of_dataset=None):\n",
    "            if table_of_coef is None:\n",
    "                table_of_coef = pd.DataFrame([[1.0,-0.11,1.0,-1.0],\n",
    "                                     [1.0,-0.22,1.0,-1.0],\n",
    "                                      [1.0,-0.11,1.0,-2.0]])\n",
    "                table_of_coef.index = ['Standart','LowFP','LowFN']\n",
    "                table_of_coef.index.name = \"Metric\"\n",
    "                table_of_coef.columns = ['A_tp','A_fp','A_tn','A_fn']\n",
    "\n",
    "            alist = detecting_boundaries.copy()\n",
    "            prediction = prediction.copy()\n",
    "\n",
    "            Scores, Scores_perfect, Scores_null=[], [], []\n",
    "            for profile in ['Standart', 'LowFP', 'LowFN']:       \n",
    "                A_tp = table_of_coef['A_tp'][profile]\n",
    "                A_fp = table_of_coef['A_fp'][profile]\n",
    "                A_fn = table_of_coef['A_fn'][profile]\n",
    "                def sigm_scale(y, A_tp, A_fp, window=1):\n",
    "                    return (A_tp-A_fp)*(1/(1+np.exp(5*y/window))) + A_fp\n",
    "\n",
    "                #First part\n",
    "                score = 0\n",
    "                if len(alist)>0:\n",
    "                    score += prediction[:alist[0][0]].sum()*A_fp\n",
    "                else:\n",
    "                    score += prediction.sum()*A_fp\n",
    "                #second part\n",
    "                for i in range(len(alist)):\n",
    "                    if i<=len(alist)-2:\n",
    "                        win_space = prediction[alist[i][0]:alist[i+1][0]].copy()\n",
    "                    else:\n",
    "                        win_space = prediction[alist[i][0]:].copy()\n",
    "                    win_fault = prediction[alist[i][0]:alist[i][1]]\n",
    "                    slow_width = int(len(win_fault)/4)\n",
    "\n",
    "                    if len(win_fault) + slow_width >= len(win_space):\n",
    "#                         print(f'Intersection of the windows of too wide widths for dataset {name_of_dataset}')\n",
    "                        win_fault_slow = win_fault.copy()\n",
    "                    else:\n",
    "                        win_fault_slow= win_space[:len(win_fault)  +  slow_width]\n",
    "\n",
    "                    win_fp = win_space[-len(win_fault_slow):]\n",
    "\n",
    "                    if win_fault_slow.sum() == 0:\n",
    "                        score+=A_fn\n",
    "                    else:\n",
    "                        #to get the first index\n",
    "                        tr = pd.Series(win_fault_slow.values,index = range(-len(win_fault), len(win_fault_slow)-len(win_fault)))\n",
    "                        tr_values= tr[tr==1].index[0]\n",
    "                        tr_score = sigm_scale(tr_values, A_tp,A_fp,slow_width)\n",
    "                        score += tr_score\n",
    "                        score += win_fp.sum()*A_fp\n",
    "                Scores.append(score)\n",
    "                Scores_perfect.append(len(alist)*A_tp)\n",
    "                Scores_null.append(len(alist)*A_fn)\n",
    "            return np.array([np.array(Scores),np.array(Scores_null), np.array(Scores_perfect)])\n",
    "       #======      \n",
    "        if type(prediction) != type(list()):\n",
    "            matrix = single_evaluate_nab(detecting_boundaries, prediction, table_of_coef=table_of_coef)\n",
    "        else:\n",
    "            matrix = np.zeros((3,3))\n",
    "            for i in range(len(prediction)):\n",
    "                matrix_ = single_evaluate_nab(detecting_boundaries[i], prediction[i], table_of_coef=table_of_coef,name_of_dataset=i)\n",
    "                matrix = matrix + matrix_      \n",
    "                \n",
    "        results = {}\n",
    "        desc = ['Standart', 'LowFP', 'LowFN'] \n",
    "        for t, profile_name in enumerate(desc):\n",
    "            results[profile_name] = round(100*(matrix[0,t]-matrix[1,t])/(matrix[2,t]-matrix[1,t]), 2)\n",
    "            print(profile_name,' - ', results[profile_name])\n",
    "        \n",
    "        return results\n",
    "            \n",
    "            \n",
    "    #=========================================================================\n",
    "    if type(true) != type(list()):\n",
    "        true_items = true[true==1].index\n",
    "    else:\n",
    "        true_items = [true[i][true[i]==1].index for i in range(len(true))]\n",
    "        \n",
    "\n",
    "    if not metric=='binary':\n",
    "        def single_detecting_boundaries(true, numenta_time, true_items):\n",
    "            detecting_boundaries=[]\n",
    "            td = pd.Timedelta(numenta_time) if numenta_time is not None else pd.Timedelta((true.index[-1]-true.index[0])/len(true_items))  \n",
    "            for val in true_items:\n",
    "                detecting_boundaries.append([val, val + td])\n",
    "            return detecting_boundaries\n",
    "        \n",
    "        if type(true) != type(list()):\n",
    "            detecting_boundaries = single_detecting_boundaries(true=true, numenta_time=numenta_time, true_items=true_items)\n",
    "        else:\n",
    "            detecting_boundaries=[]\n",
    "            for i in range(len(true)):\n",
    "                detecting_boundaries.append(single_detecting_boundaries(true=true[i], numenta_time=numenta_time, true_items=true_items[i]))\n",
    "\n",
    "    if metric== 'nab':\n",
    "        return evaluate_nab(detecting_boundaries, prediction)\n",
    "    elif metric=='average_delay':\n",
    "        return average_delay(detecting_boundaries, prediction)\n",
    "    elif metric== 'binary':\n",
    "        return binary(true, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e235b6",
   "metadata": {},
   "source": [
    "<h3>binseg</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ae4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binseg(cost, data, params):\n",
    "    predicted_cp = []\n",
    "    for dataset in data:\n",
    "        stsc = StandardScaler()\n",
    "        signal = stsc.fit_transform(dataset.drop('changepoint', axis=1))\n",
    "        algo = rpt.Binseg(model=cost, \n",
    "                          params=params,\n",
    "                          jump=5)\n",
    "        algo.fit(signal)\n",
    "        my_bkps = algo.predict(n_bkps=len(dataset[dataset['changepoint']==1]))\n",
    "        \n",
    "        single_predicted_cp = pd.Series(data=0, index=dataset.index)\n",
    "        single_predicted_cp[single_predicted_cp.index[my_bkps[:-1]]] = 1\n",
    "        predicted_cp.append(single_predicted_cp)\n",
    "\n",
    "    true_cp = [dataset.changepoint for dataset in data]\n",
    "    nab = evaluating_change_point(true_cp, predicted_cp, metric='nab', numenta_time='30 sec')\n",
    "    return nab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (\n",
    "    {'cost':'ar', 'params':{'order':1}},\n",
    "    {'cost':'mahalanobis', 'params':{}},\n",
    "    {'cost':'l1', 'params':{}},\n",
    "    {'cost':'l2', 'params':{}},\n",
    "    {'cost':'linear', 'params':{}},\n",
    ")\n",
    "\n",
    "table = []\n",
    "for model in tqdm(models, desc='agg functions loop'):\n",
    "    table.append(binseg(**model, data=test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5910cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(table).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e138e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
